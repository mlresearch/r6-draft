---
abstract: Planning can often be simplified by decomposing the task into smaller tasks
  arranged hierarchically. Charlin et al. [4] recently showed that the hierarchy discovery
  problem can be framed as a non-convex optimization problem. However, the inherent
  computational difficulty of solving such an optimization problem makes it hard to
  scale to real-world problems. In another line of research, Toussaint et al. [18]
  developed a method to solve planning problems by maximum-likelihood estimation.
  In this paper, we show how the hierarchy discovery problem in partially observable
  domains can be tackled using a similar maximum likelihood approach. Our technique
  first transforms the problem into a dynamic Bayesian network through which a hierarchical
  structure can naturally be discovered while optimizing the policy. Experimental
  results demonstrate that this approach scales better than previous techniques based
  on non-convex optimization.
title: Hierarchical POMDP controller optimization by likelihood maximization
year: '2008'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: toussaint08a
month: 0
tex_title: Hierarchical POMDP controller optimization by likelihood maximization
firstpage: 562
lastpage: 570
page: 562-570
order: 562
cycles: false
bibtex_author: Toussaint, Marc and Charlin, Laurent and Poupart, Pascal
author:
- given: Marc
  family: Toussaint
- given: Laurent
  family: Charlin
- given: Pascal
  family: Poupart
date: 2008-07-09
note: Reissued by PMLR on 09 October 2024.
address:
container-title: Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence
volume: R6
genre: inproceedings
issued:
  date-parts:
  - 2008
  - 7
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/r6/main/assets/toussaint08a/toussaint08a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
