---
abstract: Model-based Bayesian reinforcement learning has generated significant interest
  in the AI community as it provides an elegant solution to the optimal exploration-exploitation
  tradeoff in classical reinforcement learning. Unfortunately, the applicability of
  this type of approach has been limited to small domains due to the high complexity
  of reasoning about the joint posterior over model parameters. In this paper, we
  consider the use of factored representations combined with online planning techniques,
  to improve scalability of these methods. The main contribution of this paper is
  a Bayesian framework for learning the structure and parameters of a dynamical system,
  while also simultaneously planning a (near-)optimal sequence of actions.
title: Model-based Bayesian reinforcement learning in large structured domains
year: '2008'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ross08a
month: 0
tex_title: Model-based Bayesian reinforcement learning in large structured domains
firstpage: 476
lastpage: 483
page: 476-483
order: 476
cycles: false
bibtex_author: Ross, St\'{e}phane and Pineau, Joelle
author:
- given: St√©phane
  family: Ross
- given: Joelle
  family: Pineau
date: 2008-07-09
note: Reissued by PMLR on 09 October 2024.
address:
container-title: Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence
volume: R6
genre: inproceedings
issued:
  date-parts:
  - 2008
  - 7
  - 9
pdf: https://raw.githubusercontent.com/mlresearch/r6/main/assets/ross08a/ross08a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
