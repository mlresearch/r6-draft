---
title: 'Continuous time dynamic topic models'
abstract: 'In this paper, we develop the continuous time dynamic topic model (cDTM). The cDTM is a dynamic topic model that uses Brownian motion to model the latent topics through a sequential collection of documents, where a "topic" is a pattern of word use that we expect to evolve over the course of the collection. We derive an efficient variational approximate inference algorithm that takes advantage of the sparsity of observations in text, a property that lets us easily handle many time points. In contrast to the cDTM, the original discrete-time dynamic topic model (dDTM) requires that time be discretized. Moreover, the complexity of variational inference for the dDTM grows quickly as time granularity increases, a drawback which limits fine-grained discretization. We demonstrate the cDTM on two news corpora, reporting both predictive perplexity and the novel task of time stamp prediction.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang08a
month: 0
tex_title: "Continuous time dynamic topic models"
firstpage: 579
lastpage: 586
page: 579-586
order: 579
cycles: false
bibtex_editor: McAllester, David A. and Myllymäki, Petri
editor:
- given: David A.
  family: McAllester
- given: Petri
  family: Myllymäki
bibtex_author: Wang, Chong and Blei, David and Heckerman, David
author:
- given: Chong
  family: Wang
- given: David
  family: Blei
- given: David
  family: Heckerman 
date: 2008-07-09
note: Reissued by PMLR on 30 October 2024.
address:
container-title: Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence
volume: R6
genre: inproceedings
issued:
  date-parts:
  - 2008
  - 7
  - 9
pdf: http://proceedings.mlr.press/r6/wang08a/wang08a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
